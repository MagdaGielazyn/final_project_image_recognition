{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MagdaGielazyn/final_project_image_recognition/blob/master/MRI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEt6Dnc6YFTd"
      },
      "source": [
        "<span style=\"color: lightblue\">\n",
        "\n",
        "# ML - PROJEKT ZALICZENIOWY\n",
        "### 1. Project overview\n",
        "\n",
        "<span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk5zccvwKg-l"
      },
      "outputs": [],
      "source": [
        "#import bibliotek:\n",
        "import hashlib\n",
        "import kagglehub\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pobierzmy dane na wypadek, gdyby autor zbioru dokonywal zmian"
      ],
      "metadata": {
        "id": "b7Hk3rW8RHIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funkcje, ktore wrzucimy do folderku utils:"
      ],
      "metadata": {
        "id": "pvfmXKfLRPOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNEBKDZXgefk"
      },
      "outputs": [],
      "source": [
        "#sprawdzenie balansu rozlozenia klas w zbiorze:\n",
        "def check_balance(df, target):\n",
        "    df_percentage = df[target].value_counts(normalize=True) * 100\n",
        "    num = df_percentage.max()\n",
        "    if num == 25:\n",
        "        descr = \"Dane są idealnie zrównoważone.\"\n",
        "    elif num <= 35:\n",
        "        descr = \"Dane są dobrze zrównoważone.\"\n",
        "    elif num <= 45:\n",
        "        descr = \"Lekka nierównowaga – akceptowalna.\"\n",
        "    elif num <= 55:\n",
        "        descr = \"Umiarkowana nierównowaga – warto monitorować.\"\n",
        "    else:\n",
        "        descr = \"Silna nierównowaga – zalecane balansowanie danych.\"\n",
        "    return descr\n",
        "\n",
        "#wczytanie danych:\n",
        "def data_reader(path: str, img_size=(150, 150), batch_size=None):\n",
        "    dataset_path = kagglehub.dataset_download(path)\n",
        "    train_dir = os.path.join(dataset_path, \"Training\")\n",
        "    test_dir = os.path.join(dataset_path, \"Testing\")\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        train_dir,\n",
        "        image_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode=\"categorical\",\n",
        "        shuffle=False, ### na razie tak zamiast False zeby sciezki podpiac\n",
        "    )\n",
        "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        test_dir,\n",
        "        image_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode=\"categorical\",\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    train_paths = tf.data.Dataset.from_tensor_slices(train_ds.file_paths)\n",
        "    test_paths = tf.data.Dataset.from_tensor_slices(test_ds.file_paths)\n",
        "\n",
        "\n",
        "    enriched_train_ds = tf.data.Dataset.zip((train_ds, train_paths))\n",
        "    enriched_test_ds = tf.data.Dataset.zip((test_ds, test_paths))\n",
        "    full_ds=enriched_train_ds.concatenate(enriched_test_ds)\n",
        "\n",
        "    categories = set(train_ds.class_names+test_ds.class_names)\n",
        "    #train_ds = train_ds.batch(batch_size)\n",
        "    #test_ds = test_ds.batch(batch_size)\n",
        "\n",
        "    return (full_ds, categories, train_ds, test_ds)\n",
        "\n",
        "#zmiana datasetu na df:\n",
        "def batched_dataset_to_df(ds):\n",
        "    return pd.DataFrame([\n",
        "        (p.numpy().decode(), int(np.argmax(y.numpy())))\n",
        "        for (x, y), ps in ds\n",
        "        for p, y in zip(ps, y)\n",
        "    ], columns=[\"path\", \"label\"])\n",
        "def dataset_to_df(ds):\n",
        "    return pd.DataFrame([\n",
        "        (path.numpy().decode(), int(np.argmax(label.numpy())))\n",
        "        for (image, label), path in ds\n",
        "    ], columns=[\"path\", \"label\"])\n",
        "\n",
        "#znalezienie duplikatow:\n",
        "def find_image_duplicates(**kwargs):\n",
        "    datasets = list(kwargs.values())\n",
        "    def image_hash(image):\n",
        "      image_bytes = tf.io.serialize_tensor(image)\n",
        "      return hashlib.md5(image_bytes.numpy()).hexdigest()\n",
        "    if not datasets:\n",
        "        return {\n",
        "            \"Liczba wszystkich obrazów:\": 0,\n",
        "            \"Liczba duplikatów:\": 0,\n",
        "            \"Unikalne obrazy:\": 0,\n",
        "            \"Duplikaty szczegóły:\": []\n",
        "        }\n",
        "\n",
        "    full_ds = datasets[0]\n",
        "    for ds in datasets[1:]:\n",
        "        full_ds = full_ds.concatenate(ds)\n",
        "\n",
        "    hash_to_path = {}\n",
        "    duplicates = []\n",
        "    total_images = 0\n",
        "\n",
        "    for (img, _), path in full_ds:\n",
        "      total_images += 1\n",
        "      h = image_hash(img)\n",
        "      #print(h)\n",
        "      path_str = path.numpy().decode()\n",
        "\n",
        "      if h in hash_to_path:\n",
        "\n",
        "          duplicates.append((path_str, hash_to_path[h]))\n",
        "      else:\n",
        "\n",
        "          hash_to_path[h] = path_str\n",
        "\n",
        "    return {\n",
        "        \"Number of images\": total_images,\n",
        "        \"Number of duplicates\": len(duplicates),\n",
        "        \"Unique images\": len(hash_to_path),\n",
        "        \"Duplicates details\": duplicates\n",
        "    }\n",
        "\n",
        "#pokazanie rozdystrybuuowania klas w zbiorze:\n",
        "def plot_class_distribution(df, column=\"label_name\", title=\"Rozkład klas\"):\n",
        "    labels = df[column].value_counts().index.tolist()\n",
        "    colors = sns.color_palette(\"Blues\", n_colors=len(labels))\n",
        "\n",
        "    df[column].value_counts(normalize=True).plot(\n",
        "        kind=\"pie\",\n",
        "        autopct=\"%1.1f%%\",\n",
        "        labels=labels,\n",
        "        colors=colors,\n",
        "        title=title,\n",
        "        ylabel=\"\"\n",
        "    )\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "#usuniecie zduplikowanych obrazow:\n",
        "def remove_paths_from_dataset(dataset, paths_to_remove):\n",
        "    paths_to_remove = tf.constant(paths_to_remove)\n",
        "    def keep_fn(data, path):\n",
        "        is_equal = tf.reduce_any(tf.equal(paths_to_remove, path))\n",
        "        return tf.logical_not(is_equal)\n",
        "\n",
        "    return dataset.filter(keep_fn)\n",
        "\n",
        "\n",
        "#pokazanie obrazow ze zbiorow:\n",
        "def show_images(paths, rows=None, cols=None, figsize=(16, 8)):\n",
        "    n = len(paths)\n",
        "    if rows is None and cols is None:\n",
        "        cols = min(5, n)\n",
        "        rows = math.ceil(n / cols)\n",
        "    elif rows is None:\n",
        "        rows = math.ceil(n / cols)\n",
        "    elif cols is None:\n",
        "        cols = math.ceil(n / rows)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    for i, path in enumerate(paths, 1):\n",
        "        img = Image.open(path)\n",
        "        plt.subplot(rows, cols, i)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "#podzial datasetu na traningowy i testowy:\n",
        "def split_train_test_ds(dataset, dataset_size, split_ratio=0.2, batch_size=32, limit_ds=None):\n",
        "    dataset = dataset.shuffle(buffer_size=dataset_size)\n",
        "    split_index = int(dataset_size * split_ratio)\n",
        "    train_dataset = dataset.skip(split_index)\n",
        "    #train_dataset = train_dataset.batch(batch_size)\n",
        "    test_dataset = dataset.take(split_index)\n",
        "    #test_dataset = test_dataset.batch(batch_size)\n",
        "    if limit_ds is not None:\n",
        "        train_ratio = sum(1 for _ in train_dataset)*limit_ds\n",
        "        test_ratio = sum(1 for _ in test_dataset)*limit_ds\n",
        "        train_dataset = train_dataset.take(train_ratio)\n",
        "        test_dataset = test_dataset.take(test_ratio)\n",
        "    return train_dataset, test_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JksQKAfJNPli"
      },
      "source": [
        "**Problem badawczy:** Zbudowanie i ocena modelu klasyfikacji obrazów MRI mózgu z wykorzystaniem sieci konwolucyjnej (CNN – Convolutional Neural Network). Model ma rozpoznawać rodzaj obrazu MRI spośród czterech kategorii:\n",
        "\n",
        "*   Glioma tumor - Glejak\n",
        "*   Meningioma tumor - Oponiak\n",
        "*   Pituitary tumor - Guz przysadki mózgowej\n",
        "*   No tumor - Brak guza (pacjent zdrowy)\n",
        "\n",
        "Zadanie to jest przykładem klasyfikacji binominalnej obrazów medycznych.\n",
        "\n",
        "\n",
        "Analiza obrazów MRI jest kluczowa w diagnostyce chorób mózgu, ale wymaga czasu i specjalistycznej wiedzy. Automatyczne modele oparte na uczeniu głębokim, takie jak CNN, mogą wspierać lekarzy w szybszym i bardziej obiektywnym wstępnym rozpoznaniu typu guza lub jego braku. Projekt ma na celu sprawdzenie, jak dobrze prosty model CNN radzi sobie z takim zadaniem.\n",
        "\n",
        "Opis danych\n",
        "W projekcie wykorzystano publiczny zbiór danych z platformy Kaggle: Brain Tumor MRI Dataset. Zbiór zawiera obrazy MRI mózgu podzielone na foldery odpowiadające czterem klasom. Dane są już rozdzielone na zbiór treningowy (Training) oraz testowy (Testing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urOIWvkAKJgb"
      },
      "outputs": [],
      "source": [
        "#pobranie danych i wczytanie danych - dane laczymy by pozniej sprawdzic czy nie ma duplikatow\n",
        "full_ds, categories, tr, ts = data_reader(\"masoudnickparvar/brain-tumor-mri-dataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sprawdzenie katergorii (etykiet)\n",
        "categories"
      ],
      "metadata": {
        "id": "31vBOIDM9CL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#opis datasetu\n",
        "full_ds"
      ],
      "metadata": {
        "id": "7-EwzLLj8HOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Sowcy72EgKQ"
      },
      "outputs": [],
      "source": [
        "#sprawdzenie reczne  etykiet w one hot encoding dla 5 pierwszych losowych etykiet\n",
        "for (_, labels),_  in full_ds.shuffle(7200).take(5):\n",
        "    print(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3k22CafK5Im"
      },
      "outputs": [],
      "source": [
        "#sprawdzenie reczne tensorow obrazow dla 1 pierwszego obrazka\n",
        "for (images, _),_  in full_ds.take(1):\n",
        "    print(images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvkozrHtYNDE"
      },
      "source": [
        "<span style=\"color: lightblue\">\n",
        "\n",
        "### 2.  EDA - Explanatory data analysis\n",
        "\n",
        "<span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlN0HHKuX8Y6"
      },
      "outputs": [],
      "source": [
        "#sprawdzenie czy mamy zduplikowane obrazy w datasecie - zbiory tetsowy i treningowy wczesniej zostaly polaczone w calosc by uniknac duplikatow\n",
        "#pomiedzy zbiorem treningowym a testowym, ktore moglyby spowdowac przeuczenie sie\n",
        "\n",
        "duplicates = find_image_duplicates(full_ds=full_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates"
      ],
      "metadata": {
        "id": "eYD2Dp5GRh5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wizualizacja przykladowych duplikatow:\n",
        "show_images(['/kaggle/input/brain-tumor-mri-dataset/Training/meningioma/Tr-me_1242.jpg', '/kaggle/input/brain-tumor-mri-dataset/Training/meningioma/Tr-aug-me_90.jpg', '/kaggle/input/brain-tumor-mri-dataset/Training/meningioma/Tr-me_1274.jpg',\n",
        "   '/kaggle/input/brain-tumor-mri-dataset/Training/meningioma/Tr-aug-me_98.jpg', '/kaggle/input/brain-tumor-mri-dataset/Testing/notumor/Te-no_92.jpg',\n",
        "   '/kaggle/input/brain-tumor-mri-dataset/Training/notumor/Tr-no_1319.jpg', '/kaggle/input/brain-tumor-mri-dataset/Testing/notumor/Te-no_194.jpg',\n",
        "   '/kaggle/input/brain-tumor-mri-dataset/Training/notumor/Tr-no_1004.jpg'], rows = 2, cols = 4)"
      ],
      "metadata": {
        "id": "um8dDFbg0pOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Identyfikacja duplikatow do usuniecia\n",
        "paths_to_remove = [e[0] for e in duplicates['Duplicates details']]"
      ],
      "metadata": {
        "id": "7auFzsIWC7gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#usuniecie duplikatow\n",
        "deduplicated_ds = remove_paths_from_dataset(full_ds, paths_to_remove)"
      ],
      "metadata": {
        "id": "KwK9EJ1_EG5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ponowne sprawdzenie czy nie ma duplikatow w celu upewnienia sie, ze zostaly usuniete porpawnie:\n",
        "final_stat = find_image_duplicates(deduplicated_ds=deduplicated_ds)\n",
        "final_stat"
      ],
      "metadata": {
        "id": "uCvd5lAFEh-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#podzial zbiory na zbior testowy i traningowy\n",
        "train_ds, test_ds = split_train_test_ds(deduplicated_ds, final_stat['Number of images'], 0.3)"
      ],
      "metadata": {
        "id": "x2RojncrExuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#opis traningowego datasetu:\n",
        "train_ds"
      ],
      "metadata": {
        "id": "2_yH_4C8HM2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#opis testowego datasetu:\n",
        "test_ds"
      ],
      "metadata": {
        "id": "874N3ZeuUR--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#zmiana datasetu treningowego na df:\n",
        "train_df = dataset_to_df(train_ds)\n",
        "train_df.head(100)"
      ],
      "metadata": {
        "id": "6uNS7kEgUmj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#zmiana datasetu treningowego na df:\n",
        "test_df = dataset_to_df(test_ds)\n",
        "test_df.head(100)"
      ],
      "metadata": {
        "id": "0asOyVpKVA0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wyciagniecie nazwy etykiety dla konkretnej labelki zbioru treningowego\n",
        "train_df[\"label_name\"] = train_df[\"path\"].apply(lambda p: p.split(\"/\")[-2])"
      ],
      "metadata": {
        "id": "S6TNzwi0V7hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPIYS2pEi5U6"
      },
      "outputs": [],
      "source": [
        "#pokazanie rozkladu klas w zbiorze treningowym\n",
        "plot_class_distribution(train_df, \"label_name\", \"Rozkład klas w zbiorze treningowym\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q7YLZR2mWCI"
      },
      "outputs": [],
      "source": [
        "#sprawdzenie czy balans rozkladu klas w zbiorze treningowym jest prawidlowo zrownowazony\n",
        "check_balance(train_df, 'label_name')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wyciagniecie nazwy etykiety dla konkretnej labelki zbioru testowego\n",
        "test_df[\"label_name\"] = train_df[\"path\"].apply(lambda p: p.split(\"/\")[-2])"
      ],
      "metadata": {
        "id": "cvekqj73XEYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pokazanie rozkladu klas w zbiorze testowym\n",
        "plot_class_distribution(test_df, \"label_name\", \"Rozkład klas w zbiorze testowym\")"
      ],
      "metadata": {
        "id": "IEkL2xIwX-d3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXkAuldFmz--"
      },
      "outputs": [],
      "source": [
        "#sprawdzenie czy balans rozkladu klas w zbiorze testowym jest prawidlowo zrownowazony\n",
        "check_balance(test_df, 'label_name')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ans21lOllVSQ"
      },
      "source": [
        "**Wniosek ogolny:** Rozkład klas w zbiorze treningowym i testowym jest identyczny, co wskazuje na prawidłowy podział danych. Zbiory są  zbalansowane, co sprzyja stabilnemu trenowaniu modelu klasyfikacyjnego"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUssd68_tKRV"
      },
      "outputs": [],
      "source": [
        "#Wizualizacja przykladowych obrazow:\n",
        "sample = train_df.sample(n=15, random_state=42)\n",
        "show_images(paths=sample[\"path\"].tolist(), rows=3, cols=5)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxyEAS01yCV0"
      },
      "source": [
        "**Wnioski:**\n",
        "\n",
        "\n",
        "*   Kolorystyka obrazow rozni sie - czesc obrazow jest czarnobiala, a czesc w kolorach -> Potrzebna normalizacja\n",
        "*   Jasnosc i kontrast sa zroznicowane nawet w ramach odcieni czerni - raz obraz jest jasniejszy, raz ciemniejszy -> Potrzebna normalizacja\n",
        "*   Obrazy mają różne rozmiary -->  Potrzebny crop\n",
        "*   Obrazy pochodzą z różnych płaszczyzn przekroju, rozne orientacje i skale --> Potrzebne filtry\n",
        "*   Na obrazach widac napisy np pasek u gory zdjecia\n",
        "*   Na obrazkach jest duzo tla\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds2 = train_ds.map(\n",
        "    lambda data, path: (tf.image.rgb_to_grayscale(data[0]), data[1])\n",
        ")\n",
        "\n",
        "test_ds2 = test_ds.map(\n",
        "    lambda data, path: (tf.image.rgb_to_grayscale(data[0]), data[1])\n",
        ")"
      ],
      "metadata": {
        "id": "GMPPbfcax6Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds2 = train_ds2.map(\n",
        "    lambda x, y: (tf.image.central_crop(x, 0.8), y)\n",
        ")\n",
        "\n",
        "test_ds2 = test_ds2.map(\n",
        "    lambda x, y: (tf.image.central_crop(x, 0.8), y)\n",
        ")"
      ],
      "metadata": {
        "id": "mHuDZND8097t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds2 = train_ds2.map(\n",
        "    lambda x, y: (tf.image.resize(x, (150,150)), y)\n",
        ")\n",
        "\n",
        "test_ds2 = test_ds2.map(\n",
        "    lambda x, y: (tf.image.resize(x, (150,150)), y)\n",
        ")"
      ],
      "metadata": {
        "id": "vosphdVO3HA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds2 = train_ds2.map(\n",
        "    lambda x, y: (tf.cast(x, tf.float32) / 255.0, y)\n",
        ")\n",
        "\n",
        "test_ds2 = test_ds2.map(\n",
        "    lambda x, y: (tf.cast(x, tf.float32) / 255.0, y)\n",
        ")"
      ],
      "metadata": {
        "id": "qbvNWnLi1ISr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds2 = train_ds2.map(lambda x, y: (tf.image.grayscale_to_rgb(x), y))\n",
        "test_ds2  = test_ds2.map(lambda x, y: (tf.image.grayscale_to_rgb(x), y))"
      ],
      "metadata": {
        "id": "wbW8JOD1Z_E3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augment = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.05),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "train_ds2 = train_ds2.map(lambda x,y: (augment(x), y))"
      ],
      "metadata": {
        "id": "gPidciXP1U3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds2.element_spec)"
      ],
      "metadata": {
        "id": "FIHzwNhzyvxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qz2aGluYcnN"
      },
      "outputs": [],
      "source": [
        "#jakie inne operacje?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXnMoVFEMYS7"
      },
      "source": [
        "<span style=\"color: lightblue\">\n",
        "\n",
        "### 3. Model\n",
        "\n",
        "<span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_F-3vhSoaAom"
      },
      "outputs": [],
      "source": [
        "# unet i potem drugi model (czy mozna np xgboost na obrazki?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Iau_pYxoRdP"
      },
      "outputs": [],
      "source": [
        "#tu zdecydowanie trzeba poprawic, wrzucilam tak o, nie myslalam o tym jeszcze\n",
        "\n",
        "def unet_like_model():\n",
        "    inputs = tf.keras.Input(shape=(150, 150, 3), dtype=\"float32\")\n",
        "\n",
        "    # Encoder\n",
        "    x = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(inputs)\n",
        "    x = tf.keras.layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
        "    x = tf.keras.layers.MaxPooling2D((2,2))(x)\n",
        "\n",
        "    # Bottleneck\n",
        "    x = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
        "\n",
        "    # Decoder (bardzo uproszczony)\n",
        "    x = tf.keras.layers.UpSampling2D((2,2))(x)\n",
        "    x = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
        "\n",
        "      # Decoder (bardzo uproszczony)\n",
        "    x = tf.keras.layers.UpSampling2D((2,2))(x)\n",
        "    x = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = tf.keras.layers.Dense(4, activation=\"softmax\")(x)\n",
        "\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model = unet_like_model()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cKqAbmypzgT"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        "    #learning_rate=0.001\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds2"
      ],
      "metadata": {
        "id": "yS-BuTW8XXRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr.batch(32)"
      ],
      "metadata": {
        "id": "wKljGW56Z4b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds2"
      ],
      "metadata": {
        "id": "ukawjWdncZaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batched_train_ds2 = train_ds2.batch(32)\n",
        "batched_test_ds2 = test_ds2.batch(32)"
      ],
      "metadata": {
        "id": "xlRPCsDRbptb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batched_train_ds2"
      ],
      "metadata": {
        "id": "ZjoFW0Ynb1vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEMzvWFhOuax"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    batched_train_ds2,\n",
        "    validation_data=batched_test_ds2,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQ6Zll06Nt13"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOoAA-zRPuIY"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_ds, verbose=0)\n",
        "\n",
        "print(f\"Dokładność na zbiorze testowym: {accuracy:.4f}\")\n",
        "print(f\"Strata na zbiorze testowym: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYuCBzBWNBTs"
      },
      "outputs": [],
      "source": [
        "#dodalabym confusion matrix (w postaci diagramu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nc9u09UXZmLl"
      },
      "outputs": [],
      "source": [
        "#metryki: recall i precision,  accuracy, f1 score etc\n",
        "#heatmapa do metryk\n",
        "#moglibysmy tez zrobic wizualizacje - obrazek i pod spodem info czy trag=filismy czy nie, robilismy cos takiego z Kuba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgbeV2DQMoRC"
      },
      "source": [
        "<span style=\"color: lightblue\">\n",
        "\n",
        "### 4. Optymalizacja\n",
        "\n",
        "<span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t_uZAQ4My6h"
      },
      "outputs": [],
      "source": [
        "#tu optuna :) uzyjmy slajdow Natalii by zidentyfiukowac ktore parametry chcemy podrasowac (ostatnia przeka z architektury z zajec)\n",
        "\n",
        "# Wypisać prametry do optymalizacji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFrjrj3_MsPu"
      },
      "source": [
        "<span style=\"color: lightblue\">\n",
        "\n",
        "### 5. Wnioski\n",
        "\n",
        "<span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEnvzifPNI5D"
      },
      "outputs": [],
      "source": [
        "#wylistowac wnioski\n",
        "#sprawdzic w chat i w internecie czy jest do obrazkow cos na podobienstwo shapa i jesli tak to uzyc"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}